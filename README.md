Designed a rule-driven Blackjack simulator using object-oriented state machines, implementing hand
valuation, dealer policies, bust logic, and win–loss resolution with clean game mechanics and terminal visualisation
Implemented a Monte Carlo reinforcement learning agent to learn optimal state–action policies from episodic
interaction, using return averaging, policy evaluation, and iterative improvement in a stochastic environment
Engineered a modular game engine architecture with deck abstraction, dynamic Ace handling, state transitions,
and structured reward signals to enable scalable RL training, experimentation, and policy evaluation